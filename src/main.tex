% Stanford University PhD thesis style -- modifications to the report style
% This is unofficial so you should always double check against the
% Registrar's office rules
% See http://library.stanford.edu/research/bibliography-management/latex-and-bibtex
% 
% Example of use below
% See the suthesis-2e.sty file for documentation
%
% !TEX root = relative/or/absolute/path/to/root/file.tex
\documentclass{report}
\usepackage{suthesis-2e}
\usepackage{graphicx}
\usepackage{verbatim} % for block comment
\usepackage{color}   % May be necessary if you want to color links
\usepackage{hyperref}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{dblfloatfix}
\usepackage[backend=bibtex,style=ieee,natbib=true]{biblatex} % Use the bibtex backend with the authoryear citation style (which resembles APA)
\usepackage{listings}\definecolor{listinggray}{gray}{0.9}
\newcommand\mycommfont[1]{\footnotesize\ttfamily\textcolor{blue}{#1}}
\SetCommentSty{mycommfont}
\definecolor{lbcolor}{rgb}{0.9,0.9,0.9}
\lstset{
backgroundcolor=\color{lbcolor},
tabsize=4,
%   rulecolor=,
language=[GNU]C++,
basicstyle=\scriptsize,
upquote=true,
aboveskip={1.5\baselineskip},
columns=fixed,
showstringspaces=false,
extendedchars=false,
breaklines=true,
prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
frame=single,
numbers=left,
showtabs=false,
showspaces=false,
showstringspaces=false,
identifierstyle=\ttfamily,
keywordstyle=\color[rgb]{0,0,1},
commentstyle=\color[rgb]{0.026,0.112,0.095},
stringstyle=\color[rgb]{0.627,0.126,0.941},
numberstyle=\color[rgb]{0.205, 0.142, 0.73},
%        \lstdefinestyle{C++}{language=C++,style=numbers}â€™.
}
\lstset{
backgroundcolor=\color{lbcolor},
tabsize=4,
language=C++,
captionpos=b,
tabsize=3,
frame=lines,
numbers=left,
numberstyle=\tiny,
numbersep=5pt,
breaklines=true,
showstringspaces=false,
basicstyle=\footnotesize,
%  identifierstyle=\color{magenta},
keywordstyle=\color[rgb]{0,0,1},
commentstyle=\color{Darkgreen},
stringstyle=\color{red}
}

%\usepackage{xcolor}
%\lstset { %
%    numbers=left,
%    numberstyle=\tiny,
%    stepnumber=1,
%    numbersep=5pt
%    language=C++,
%%    backgroundcolor=\color{black!5}, % set backgroundcolor
%%    basicstyle=\footnotesize,% basic font setting
%}

\addbibresource{../src/mybib.bib} % The filename of the bibliography
\hypersetup{
colorlinks=false, %set true if you want colored links
linktoc=all,     %set to all if you want both sections and subsections linked
linkcolor=black,  %choose some color if you want links to stand out
}
\dept{Electronic and Information Engineering}

\begin{document}
    \title{Fast Depth Coding in 3D-HEVC
    Using Deep Learning}
    \author{Zhen-xiang WANG}
    \principaladviser{Yui-Lam Chan}
    \beforepreface
    \prefacesection{Abstract}
    The 3D Extension of the High Efficiency Video Coding standard (3D-HEVC),
    which has been finalized by the Joint Collaborative Team on Video Coding
    (JCT-VC) in February 2015, is the new industry standard for 3D applications.
    The 3D-HEVC provides plenty of advanced coding tools specifically
    for addressing the coding of auto-stereoscopic videos which have the format
    of multiple texture views along with the depth maps which are responsible
    for synthesising intermediate views with sufficient quality for
    auto-stereoscopic display.
    The provided tools take advantage of the statistical redundancies amongst
    texture views and depth maps in the video sequences, as well as the unique
    characteristics of depth maps to significantly shrink the bit-rate
    while preserving the objective visual quality of the
    3D videos.
    However, those tools with high capability in terms of compression come
    with the high complexity of computation which has made the encoding time
    of the 3D video sequences much longer than ever by traversing a lot more
    candidates, calculating time-consuming RD Cost for each of them,
    especially in the wedgelet searching process for depth maps.
    While this full-search style method can promise to find the best
    candidate in depth intra mode decision, the time cost is expensive.

    In this dissertation we address the time cost by presenting a new
    intra mode decision method for depth maps, leveraging the deep
    convolutional neural networks to predict the wedgelet angles
    for the depth blocks.
    The predictions from the learned models are capable of
    reducing the number of wedgelet candidates by half as well as the
    angular modes in depth map coding.
    The size of the neural network has been carefully designed to balance
    the trade-off between the time cost of model prediction and the model prediction
    accuracy.
    Confusion matrix is used to monitor the training process.
    Top-K criteria is employed for the prediction.
    We have integrated the learned models into the reference software of
    3D-HEVC for the experiments.
    The compiled executable binaries are able to harness
    the power of the simultaneous computation of CPU, as well as
    the parrallel computation of GPU to accelerate the predictions.
    The simulation results show that the proposed algorithm
    provides 64.6\% time reduction in average while the
    BD performance has a tiny decrease comparing with the state-of-the-art 3D-HEVC
    standard.

    \prefacesection{Acknowledgments}
%    I would not be able to accomplish the work in this dissertation
%    if it were not for the help
%    from people.
    First and foremost, I would like to give sincere thanks to my supervisor,
    Dr.Yui-Lam Chan, for his
    extremely generous support, most insightful advices and innumerable yet
    constructive feedback.
    I learned from him to first identify a problem,
    by reading a vast amount of articles
    to know what people have achieved and what bottlenecks they have encountered.
    I learned how to read papers, how to organize them to
    become the inner comprehension.
    He guided me to use the machine learning approach to solve the
    problem that has been found in the first stage.
    Without his guidance I will not have the idea to learn the deep
    learning technology and apply it to optimize the video coding.
    His encyclopedic knowledge and charming personalities made him my mentor in
    both research and life.
    I wish to thank Dr.Sik-Ho Tsang, for our in-depth discussions from
    which I can always find useful clues to proceed to next step.
    His great expertise in video coding significantly benefits me during my
    intensive period of learning.
    Also I would like to thank my friends Alex
    and Jacky, for our
    extensive discussions about artificial intelligence
    and their applications.
    Finally thank you my parents, for the great love and constant
    encouragement which give me confidence to face and handle all the
    challenges at every moment.
    \afterpreface

    \include{Chapters/chapter1}
    \include{Chapters/chapter2}
    \include{Chapters/chapter3}
    \include{Chapters/chapter4}
    \include{Chapters/chapter5}
    \include{Chapters/chapter6}
    \include{Chapters/chapter7}
%    \appendix
%    \chapter{A Long Proof}
    \printbibliography[heading=bibintoc]
\end{document}