% Stanford University PhD thesis style -- modifications to the report style
% This is unofficial so you should always double check against the
% Registrar's office rules
% See http://library.stanford.edu/research/bibliography-management/latex-and-bibtex
% 
% Example of use below
% See the suthesis-2e.sty file for documentation
% sdf
% !TEX root = main.tex
\documentclass{report}
\usepackage{suthesis-2e}
\usepackage{graphicx}
\usepackage{svg}
\usepackage{verbatim}
\usepackage{amsmath}
\usepackage{siunitx}
% \usepackage{subfigure}
% \usepackage{subcaption}
\usepackage{mwe} %<- for dummy img
\usepackage{subcaption}
\usepackage{cleveref}
\usepackage{caption}
\sisetup{
    group-four-digits = true,
    group-separator = {,}
  }
\usepackage{float}
\usepackage{amssymb}
\let\oldemptyset\emptyset
\let\emptyset\varnothing
% \usepackage{booktabs}
\usepackage{booktabs,float,siunitx}
% \usepackage[demo]{graphicx} % omit 'demo' option in real document
% for block comment
\usepackage{color}   % May be necessary if you want to color links
\usepackage{hyperref}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{dblfloatfix}
\usepackage[backend=bibtex,style=ieee,natbib=true]{biblatex} % Use the bibtex backend with the authoryear citation style (which resembles APA)
\usepackage{listings}\definecolor{listinggray}{gray}{0.9}
\newcommand\mycommfont[1]{\footnotesize\ttfamily\textcolor{blue}{#1}}
\SetCommentSty{mycommfont}
\definecolor{lbcolor}{rgb}{0.9,0.9,0.9}
\lstset{
backgroundcolor=\color{lbcolor},
tabsize=4,
%   rulecolor=,
language=[GNU]C++,
basicstyle=\scriptsize,
upquote=true,
aboveskip={1.5\baselineskip},
columns=fixed,
showstringspaces=false,
extendedchars=false,
breaklines=true,
prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
frame=single,
numbers=left,
showtabs=false,
showspaces=false,
showstringspaces=false,
identifierstyle=\ttfamily,
keywordstyle=\color[rgb]{0,0,1},
commentstyle=\color[rgb]{0.026,0.112,0.095},
stringstyle=\color[rgb]{0.627,0.126,0.941},
numberstyle=\color[rgb]{0.205, 0.142, 0.73},
%        \lstdefinestyle{C++}{language=C++,style=numbers}â€™.
}
\lstset{
backgroundcolor=\color{lbcolor},
tabsize=4,
language=C++,
captionpos=b,
tabsize=3,
frame=lines,
numbers=left,
numberstyle=\tiny,
numbersep=5pt,
breaklines=true,
showstringspaces=false,
basicstyle=\footnotesize,
%  identifierstyle=\color{magenta},
keywordstyle=\color[rgb]{0,0,1},
commentstyle=\color{Darkgreen},
stringstyle=\color{red}
}

%\usepackage{xcolor}
%\lstset { %
%    numbers=left,
%    numberstyle=\tiny,
%    stepnumber=1,
%    numbersep=5pt
%    language=C++,
%%    backgroundcolor=\color{black!5}, % set backgroundcolor
%%    basicstyle=\footnotesize,% basic font setting
%}

\addbibresource{../src/mybib.bib} % The filename of the bibliography
\hypersetup{
colorlinks=false, %set true if you want colored links
linktoc=all,     %set to all if you want both sections and subsections linked
linkcolor=black,  %choose some color if you want links to stand out
}
\dept{Electronic and Information Engineering}

\begin{document}
    \title{Fast Depth Coding in 3D-HEVC
    Using Deep Learning}
    \author{Zhen-xiang WANG}
    \principaladviser{Yui-Lam Chan}
    \beforepreface
    \prefacesection{Abstract}
    The 3D Extension of the High Efficiency Video Coding standard (3D-HEVC),
    which has been finalized by the Joint Collaborative Team on Video Coding
    (JCT-VC) in February 2015, is the new industry standard for 3D applications.
    The 3D-HEVC provides plenty of advanced coding tools specifically
    for addressing the coding of auto-stereoscopic videos which have the format
    of multiple texture views plus depth maps which are responsible
    for synthesizing intermediate views with sufficient quality for
    auto-stereoscopic display.
    The provided tools take advantage of the statistical redundancies amongst
    texture views and depth maps in the video sequences, as well as the unique
    characteristics of depth maps to significantly shrink the bitrate
    while preserving the objective visual quality of the
    3D videos.
    However, those tools with high capabilities in terms of compression come
    with high complexity of computation which has made the encoding time
    of 3D video sequences much longer than ever by traversing a lot more
    mode candidates than all the previous standards.
    Although the current encoding scheme in the 3D-HEVC standard 
    is able to find the best
    intra mode candidate for each coding unit in depth maps, the cost
    of time for encoding is becoming a major obstacle for it to be applied
    to profitable products.

    In this dissertation we address the aforementioned time cost issue by a new
    intra mode decision algorithm for depth maps, leveraging 
    deep learning to train computational models built from neural network
    for predicting 
    the best intra angular mode
    in depth map coding.
    The predicted intra angular mode is utilized to decide the 
    most probable wedgelet by which the number of wedgelet 
    candidates can be reduced by half.
    The size of the neural network has been carefully designed to balance
    the trade-off between the complexity and accuracy in the model prediction.
    Validation precision and confusion matrix are used to monitor 
    the model training process.
    Top-k metric is adopted to make use of the predictions
    from the learned models.
    We have integrated learned models into the reference software of
    3D-HEVC for experiments.
    The compiled executable binaries are able to harness
    the power of simultaneous computation of CPU, as well as
    parallel computation of GPU to accelerate the predictions.
    The simulation results show that the proposed 
    fast depth coding algorithm
    provides 64.6\% time reduction in average while the
    BD performance has a trivial decrease comparing with 
    the state-of-the-art 3D-HEVC standard.

    \prefacesection{Acknowledgments}
%    I would not be able to accomplish the work in this dissertation
%    if it were not for the help
%    from people.
    First and foremost, I would like to give sincere thanks to my supervisor,
    Dr.Yui-Lam Chan, for his
    extremely generous support, most insightful advices and innumerable yet
    constructive feedback.
    I learned from him to first identify a problem,
    by reading a vast amount of articles
    to know what people have achieved and what bottlenecks they have encountered.
    I learned how to read papers, how to organize them to
    become the inner comprehension.
    He guided me to use the machine learning approach to solve the
    problem that has been found in the first stage.
    Without his guidance I will not have the idea to learn the deep
    learning technology and apply it to optimize the video coding.
    His encyclopedic knowledge and charming personalities made him my mentor in
    both research and life.
    I wish to thank Dr.Sik-Ho Tsang, for our in-depth discussions from
    which I can always find useful clues for next step.
    His great expertise in video coding significantly benefits me during my
    intensive period of learning.
    Also I would like to thank my friends Alex
    and Jacky, for our
    extensive discussions about artificial intelligence
    and their applications.
    Special thanks to Sue, for all the good times
    we have been together. Those indispensable
    memories always shine in my life.
    Thank you my dear parents. In the light of your 
    great love and constant encouragements, 
    I am always bursting with confidence 
    when challenges come.
    \afterpreface
    \include{Chapters/chapter1}
    \include{Chapters/chapter2}
    \include{Chapters/chapter3}
    \include{Chapters/chapter4}
    \include{Chapters/chapter5}
    \include{Chapters/chapter6}
    % \include{Chapters/chapter7}
%    \appendix
    % \chapter{Algorithm for Data Collection}\label{ch:app-algo-data-collection}
%    \chapter{Visualizations of Raw Data}\label{ch:app-visu}
    \printbibliography[heading=bibintoc]
\end{document}
